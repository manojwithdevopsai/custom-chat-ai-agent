from azure.identity import DefaultAzureCredential
from openai import AzureOpenAI
import os

# Initialize client once globally
endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
deployment_name = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME", "gpt-35-turbo-16k")

credential = DefaultAzureCredential()
client = AzureOpenAI(endpoint, credential)

def ask_llm(prompt, memory):
    # Combine conversation history from memory into the system + user messages
    messages = [
        {"role": "system", "content": "You are a helpful AI assistant."}
    ]

    # We append recent memory messages as user messages (or adapt as needed)
    for msg in memory:
        messages.append({"role": "user", "content": msg})

    # Append current prompt as user message
    messages.append({"role": "user", "content": prompt})

    response = client.chat.completions.create(
        deployment_id=deployment_name,
        messages=messages
    )

    return response.choices[0].message.content
